# Feature Specification: リアルタイム WebSocket 通信

**Feature Branch**: `008-realtime-websocket`
**Created**: 2025-12-27
**Status**: Draft
**Input**: User description: "音声入力・文字起こし・応答・音声再生をリアルタイムで表示できるように WebSocket 通信を追加したい。"

## Overview

現在の音声対話システムは HTTP リクエスト/レスポンス方式で動作しており、音声入力から応答完了まで一括で処理される。本機能では WebSocket 通信を導入し、処理の各段階（音声入力中、文字起こし中、応答生成中、音声合成中）をリアルタイムでユーザーに表示することで、応答待ち時間の体感を改善し、より対話的なユーザー体験を提供する。

## User Scenarios & Testing *(mandatory)*

### User Story 1 - リアルタイム文字起こし表示 (Priority: P1)

ユーザーが音声入力を行っている間、音声認識（STT）の結果がリアルタイムで画面に表示される。これにより、ユーザーは自分の発話が正しく認識されているかを即座に確認でき、認識エラーがあれば早期に気づくことができる。

**Why this priority**: リアルタイム性の体験向上において最も重要な機能。ユーザーが「システムが聞いている」ことを即座に確認できることで、安心感と対話的な体験を提供する。

**Independent Test**: 音声入力を開始し、話している途中で文字が画面に表示されることを確認。文字起こし完了後、完全なテキストが表示される。

**Acceptance Scenarios**:

1. **Given** ユーザーが音声入力を開始した状態, **When** ユーザーが話し始める, **Then** 話している内容の暫定的な文字起こしが画面に即座に表示される
2. **Given** 音声入力中にリアルタイム文字起こしが表示されている状態, **When** ユーザーが話し終わる, **Then** 最終的な文字起こし結果が確定表示される
3. **Given** リアルタイム文字起こしが表示されている状態, **When** 認識結果が更新される, **Then** 画面の文字がスムーズに更新される（ちらつきなし）

---

### User Story 2 - 処理状況のリアルタイム表示 (Priority: P2)

ユーザーが音声入力を送信した後、処理の各段階（音声認識完了、応答生成中、音声合成中）がリアルタイムで表示される。これにより、ユーザーはシステムが何を行っているかを把握でき、待ち時間の不安を軽減できる。

**Why this priority**: ユーザー体験の向上に重要だが、P1 の文字起こしリアルタイム表示が動作していれば、この機能がなくても基本的な価値は提供できる。

**Independent Test**: 音声入力後、画面に「応答を生成中...」「音声を合成中...」などのステータスが順次表示されることを確認。

**Acceptance Scenarios**:

1. **Given** ユーザーが音声入力を完了した状態, **When** システムが応答生成を開始する, **Then** 「応答を生成中...」というステータスが表示される
2. **Given** 応答生成が完了した状態, **When** 音声合成が開始される, **Then** ステータスが「音声を合成中...」に更新される
3. **Given** 処理状況が表示されている状態, **When** 各処理段階が完了する, **Then** ステータスが次の段階に遷移する

---

### User Story 3 - 応答テキストのストリーミング表示 (Priority: P2)

LLM が応答を生成している間、生成されたテキストが一文字ずつ（または単語ごとに）画面に表示される。これにより、ユーザーは応答の完了を待たずに内容を読み始めることができる。

**Why this priority**: ChatGPT のような対話的な体験を提供する重要な機能。P1 と同程度に重要だが、音声対話の本質ではないため P2 とする。

**Independent Test**: テキスト入力または音声入力後、AI の応答が一文字ずつ画面に表示されることを確認。

**Acceptance Scenarios**:

1. **Given** ユーザーがメッセージを送信した状態, **When** LLM が応答を生成中, **Then** 生成されたテキストがリアルタイムで画面に表示される
2. **Given** 応答テキストがストリーミング表示されている状態, **When** 全ての応答が生成完了する, **Then** 完全な応答メッセージが表示され、音声再生が開始される

---

### User Story 4 - 接続状態の可視化 (Priority: P3)

WebSocket 接続の状態（接続中、接続済み、切断）がユーザーに視覚的に表示される。接続が切れた場合は自動再接続を試み、その状況もユーザーに通知される。

**Why this priority**: システムの信頼性を示す補助的な機能。基本機能が動作していれば必須ではないが、問題発生時のデバッグとユーザー安心感のために重要。

**Independent Test**: ネットワークを一時的に切断し、接続状態表示が「切断」に変わり、再接続後に「接続済み」に戻ることを確認。

**Acceptance Scenarios**:

1. **Given** アプリケーションを開いた状態, **When** WebSocket 接続が確立される, **Then** 接続状態インジケーターが「接続済み」を示す
2. **Given** WebSocket が接続済みの状態, **When** 接続が切断される, **Then** 接続状態インジケーターが「切断」を示し、再接続を試みる
3. **Given** 再接続を試みている状態, **When** 再接続に成功する, **Then** 接続状態インジケーターが「接続済み」に戻る

---

### Edge Cases

- 音声入力中にネットワーク接続が切れた場合、入力中のデータはどうなるか？ → 入力中のデータはローカルに保持され、再接続後に送信を試みる。再接続できない場合はエラーを表示し、ユーザーに再試行を促す
- 非常に長い発話（5分以上）の場合のリアルタイム文字起こし → 既存の音声入力制限（最大60秒）を維持。制限に達した場合は自動的に送信される
- 複数のタブで同時に開いた場合の WebSocket 接続 → 各タブで独立した接続を確立。セッション状態は共有しない
- サーバー側で処理エラーが発生した場合 → エラーメッセージをリアルタイムで表示し、ユーザーに再試行オプションを提供

## Requirements *(mandatory)*

### Functional Requirements

- **FR-001**: システムはユーザーとサーバー間の双方向リアルタイム通信を確立できなければならない
- **FR-002**: システムは音声認識の中間結果をリアルタイムで表示しなければならない
- **FR-003**: システムは処理状況（認識中、応答生成中、音声合成中）をリアルタイムで表示しなければならない
- **FR-004**: システムは LLM 応答テキストをストリーミング表示しなければならない
- **FR-005**: システムは接続状態を視覚的に表示しなければならない
- **FR-006**: システムは接続が切断された場合、自動的に再接続を試みなければならない
- **FR-007**: システムは再接続の試行回数と間隔を制御しなければならない（最大5回、指数バックオフ）
- **FR-008**: システムは既存の HTTP API との後方互換性を維持しなければならない（WebSocket が使用できない環境ではフォールバック）
- **FR-009**: システムはリアルタイム更新中もスムーズなユーザーインターフェースを維持しなければならない（ちらつき・ジャンプなし）

### Key Entities

- **WebSocket Connection**: ユーザーセッションとサーバー間の双方向通信チャネル。接続状態、再接続試行回数、最終活動時刻を持つ
- **Realtime Message**: サーバーからクライアントへ送信されるリアルタイムイベント。イベントタイプ（transcript_partial, transcript_final, status_update, response_chunk, error）とペイロードを持つ
- **Processing Status**: 現在の処理段階を表す状態。recording（録音中）、transcribing（文字起こし中）、generating（応答生成中）、synthesizing（音声合成中）、playing（再生中）、idle（待機中）のいずれか

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: ユーザーの発話開始から最初の文字起こし表示まで1秒以内で表示される
- **SC-002**: LLM 応答の最初の文字が表示されるまでの時間が、現在の一括表示方式と比較して50%以上短縮される
- **SC-003**: 処理状況の更新が各段階の開始から500ミリ秒以内に画面に反映される
- **SC-004**: 接続切断から自動再接続完了まで平均10秒以内で完了する
- **SC-005**: リアルタイム更新中の画面のちらつきやジャンプが発生しない（ユーザビリティテストで95%のユーザーが「スムーズ」と評価）
- **SC-006**: WebSocket が使用できない環境でも、既存の HTTP 方式で機能が動作する（100%の後方互換性）

## Clarifications

### Session 2025-12-27

- Q: STT のリアルタイム文字起こしをどのように実現しますか？ → A: 外部ストリーミング STT サービスを使用する
- Q: WebSocket 接続時の認証はどのように行いますか？ → A: 認証なし（ローカル環境・シングルユーザー想定）

## Assumptions

- リアルタイム文字起こしには外部ストリーミング STT サービス（例：Google Speech-to-Text、Azure Speech、または Whisper ベースのストリーミング実装）を使用する。既存の ReazonSpeech/NeMo はバッチ処理用として引き続き利用可能
- 使用する LLM（OpenAI API）がストリーミングレスポンスをサポートしていると仮定（OpenAI API は標準でサポート）
- クライアントブラウザが WebSocket をサポートしていると仮定（モダンブラウザではほぼ100%サポート）
- 既存の音声入力制限（最大60秒）を維持する
- 本システムはローカル環境・シングルユーザー向けのため、WebSocket 接続時の認証は不要。将来のマルチユーザー対応時に認証機能を追加する設計余地を残す

## Out of Scope

- 音声のリアルタイムストリーミング再生（TTS 完了後に一括再生を維持）
- 複数ユーザー間のリアルタイム共有・コラボレーション機能
- WebRTC による P2P 音声通信
- オフラインモードでのリアルタイム機能
