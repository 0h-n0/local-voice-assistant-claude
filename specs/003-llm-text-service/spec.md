# Feature Specification: LLM Text Response Service

**Feature Branch**: `003-llm-text-service`
**Created**: 2025-12-26
**Status**: Draft
**Input**: User description: "OpenAI の gpt-5-mini に問い合わせてテキスト応答を生成する LLM サービスを実装したい。"

## Overview

本機能は、音声アシスタントの中核となるテキスト応答生成サービスを提供します。ユーザーからの質問やリクエストに対して、大規模言語モデル（LLM）を活用して自然で適切な日本語テキスト応答を生成します。

## Clarifications

### Session 2025-12-26

- Q: システムプロンプトの設定方法は？ → A: 固定のシステムプロンプトを設定（日本語アシスタントとして振る舞う）
- Q: 会話IDの管理方法は？ → A: クライアント側で会話IDを生成し、リクエストに含める

## User Scenarios & Testing *(mandatory)*

### User Story 1 - テキストプロンプトへの応答生成 (Priority: P1) MVP

ユーザー（またはシステム）がテキスト形式の質問やリクエストを送信すると、LLMサービスが適切な日本語テキスト応答を生成して返却します。

**Why this priority**: 音声アシスタントの基本機能として、ユーザーの質問に回答できることが最も重要です。STT（音声認識）からのテキスト入力を受け取り、応答を生成する核心機能です。

**Independent Test**: テキストメッセージを送信し、日本語の応答テキストを受け取ることで完全にテスト可能です。

**Acceptance Scenarios**:

1. **Given** サービスが起動している, **When** 「今日の天気は？」というテキストを送信する, **Then** 天気に関する自然な日本語応答が返される
2. **Given** サービスが起動している, **When** 「こんにちは」という挨拶を送信する, **Then** 適切な挨拶の応答が返される
3. **Given** サービスが起動している, **When** 空のメッセージを送信する, **Then** 適切なエラーメッセージが返される

---

### User Story 2 - 会話コンテキストの維持 (Priority: P2)

ユーザーが連続した会話を行う際、前の発話の文脈を考慮した応答を生成します。これにより、自然な対話体験を提供します。

**Why this priority**: 単発の質問応答だけでなく、文脈を理解した会話ができることで、より自然なアシスタント体験を提供できます。

**Independent Test**: 複数のメッセージを連続して送信し、前のメッセージを踏まえた応答が返されることを確認できます。

**Acceptance Scenarios**:

1. **Given** 「私の名前は田中です」と送信済み, **When** 「私の名前は何ですか？」と送信する, **Then** 「田中」という情報を含む応答が返される
2. **Given** 会話履歴がある状態, **When** 会話をリセットするリクエストを送信する, **Then** 履歴がクリアされ新しい会話が開始される

---

### User Story 3 - サービス健全性の確認 (Priority: P3)

システム管理者がLLMサービスの状態を確認し、正常に動作しているかを監視できます。

**Why this priority**: 運用時にサービスの健全性を確認できることは重要ですが、基本機能が動作した後の付加機能です。

**Independent Test**: ステータス確認リクエストを送信し、サービス状態情報を受け取ることで確認できます。

**Acceptance Scenarios**:

1. **Given** サービスが正常に起動している, **When** ステータス確認リクエストを送信する, **Then** 「正常」ステータスと接続情報が返される
2. **Given** 外部LLMサービスへの接続に問題がある, **When** ステータス確認リクエストを送信する, **Then** 「異常」ステータスとエラー詳細が返される

---

### Edge Cases

- 非常に長いメッセージ（例：10,000文字以上）を送信した場合はどうなるか？→ 適切な文字数制限とエラーメッセージを返す
- 外部LLMサービスが一時的に利用不可の場合はどうなるか？→ リトライ後、適切なエラーメッセージを返す
- 不適切なコンテンツを含むリクエストが来た場合はどうなるか？→ 外部LLMサービスのコンテンツフィルタリングに依存
- 同時に多数のリクエストが来た場合はどうなるか？→ 同時リクエスト数を制限し、超過分は待機またはエラーを返す

## Requirements *(mandatory)*

### Functional Requirements

- **FR-001**: システムはテキストメッセージを受け取り、LLMを使用して日本語テキスト応答を生成できなければならない
- **FR-002**: システムは会話のコンテキスト（履歴）を保持し、文脈を考慮した応答を生成できなければならない
- **FR-003**: システムは会話履歴をクリアする機能を提供しなければならない
- **FR-004**: システムはサービスの健全性ステータスを返すエンドポイントを提供しなければならない
- **FR-005**: システムは入力メッセージの文字数を制限し（最大4,000文字）、超過時にエラーを返さなければならない
- **FR-006**: システムは外部LLMサービスへの接続エラー時に適切なエラーメッセージを返さなければならない
- **FR-007**: システムは同時リクエスト数を制限し、リソースの枯渇を防がなければならない
- **FR-008**: システムはリクエストとレスポンスをログに記録しなければならない（個人情報を除く）
- **FR-009**: システムは固定のシステムプロンプトを使用し、日本語音声アシスタントとして一貫した振る舞いを提供しなければならない

### Key Entities

- **ChatMessage**: ユーザーまたはアシスタントからの個々のメッセージ。役割（ユーザー/アシスタント）、内容、タイムスタンプを持つ
- **Conversation**: 一連のメッセージの集合。会話ID、メッセージリスト、作成日時を持つ
- **LLMResponse**: LLMからの応答。生成されたテキスト、使用トークン数、処理時間を含む
- **ServiceStatus**: サービスの状態。接続状態、最終確認時刻、エラー情報を含む

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: ユーザーは5秒以内にテキスト応答を受け取ることができる（通常のリクエストの95%）
- **SC-002**: サービスは10件の同時リクエストを処理できる
- **SC-003**: 会話コンテキストは最低10往復（20メッセージ）まで維持される
- **SC-004**: サービス稼働率は99%以上を維持する（計画メンテナンスを除く）
- **SC-005**: エラー発生時、ユーザーは理解可能なエラーメッセージを受け取る

## Assumptions

- 外部LLMサービス（OpenAI）のAPIキーは環境変数で提供される
- gpt-5-miniモデルが利用可能であると仮定（存在しない場合は利用可能な最新の軽量モデルを使用）
- 日本語での応答生成が主な用途だが、他言語での入力も処理可能
- 会話履歴はセッション単位で管理され、サーバー再起動時にはクリアされる（永続化は将来の拡張）
- レート制限は外部LLMサービスのAPI制限に依存する

## Out of Scope

- 音声入力の処理（STTサービスが担当）
- 音声出力の生成（TTSサービスが担当）
- ユーザー認証・認可
- 会話履歴の永続化（データベース保存）
- マルチテナント対応
- カスタムプロンプト・システムメッセージの管理UI
